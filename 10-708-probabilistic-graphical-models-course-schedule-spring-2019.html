<!DOCTYPE html>
<!-- saved from url=(0054)https://sailinglab.github.io/pgm-spring-2019/lectures/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="content-language" content="en">
  
  <meta name="viewport" content="width=device-width initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>10-708 PGM | Schedule</title>
  <meta name="description" content="10-708 - Probabilistic Graphical Models - Carnegie Mellon University - Spring 2019
">

  <link rel="shortcut icon" href="https://sailinglab.github.io/pgm-spring-2019/assets/img/favicon.ico">

  <link rel="stylesheet" href="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/main.css">
  <link rel="canonical" href="https://sailinglab.github.io/pgm-spring-2019/lectures/">

  
  <!-- Load Latex JS -->
  <script async="" src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/analytics.js.download"></script><script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/latex.min.js.download"></script>
  <script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/latex.component.js.download"></script>
  
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <span class="site-title">
      <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/">10-708 PGM</a>
    </span>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"></path>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"></path>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/logistics/">logistics</a>
        <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/lectures/">lectures</a>
        <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/notes/">notes</a>
        <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/calendar/">calendar</a>
        <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/homework/">homework</a>
        <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/project/">project</a>
        <a class="page-link" href="https://sailinglab.github.io/pgm-spring-2019/reports/">reports</a>
      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Schedule</h1>
    <h2 class="post-description"></h2>
  </header>

  <article class="post-content Schedule clearfix">
    <table class="table table-hover">
      <colgroup>
        <col style="width:5%">
        <col style="width:35%">
        <col style="width:45%">
        <col style="width:15%">
      </colgroup>
      <thead class="thead-light">
        <tr>
          <th scope="col">Date</th>
          <th scope="col">Lecture</th>
          <th scope="col">Readings</th>
          <th scope="col">Logistics</th>
        </tr>
      </thead>
      <tbody>
        
<tr class="info">
    <td colspan="5" align="center"><strong>Module 1: Introduction, Representation, and Exact Inference</strong></td>
</tr>

<tr class="past">
    <th scope="row">1/14</th>
    
    <td>
        Lecture #1
        (Eric):
        <br>
        <strong>Introduction to GM</strong>

        <br>
        [
            
              <a href="https://drive.google.com/file/d/1szM2TsiL8tNYU-MlyTv4vxiFWRitZ_NS" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/file/d/1McR2fT6qGooQXMLVhOHSQsQ14lcKJKtP" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=bab0b8be-a86f-4a46-9dae-a9d0012950cb" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-01/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan, <a href="https://www.cs.cmu.edu/~epxing/Class/10708-17/reading/graphical_model_Jordan.pdf" target="_blank">Graphical Models</a></li>
        
            <li>E. Airoldi, <a href="https://dash.harvard.edu/bitstream/handle/1/2757496/Airoldi_GettingStarted.pdf" target="_blank">Getting Started in Probabilistic Graphical Models</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">1/16</th>
    
    <td>
        Lecture #2
        (Eric):
        <br>
        <strong>Representation: Directed GMs (BNs)</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1pl_IeC4N11IUMAyJnPcT_HDLHBVfB4Qx" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1OLREY-CC8OIZfY_8G1lEdqzSMsNZXHTe" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=388ec3f4-de78-4f5e-b5ca-a9d001296630" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-02/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, <a href="https://people.eecs.berkeley.edu/~jordan/prelims/chapter2.pdf" target="_blank">Ch. 2</a> (Sec. 2.1)</li>
        
            <li>Koller and Friedman Textbook, <a href="https://www.cs.cmu.edu/~epxing/Class/10708-17/readings/Ch%203.pdf" target="_blank">Ch. 3</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">1/21</th>
    
    
    <td colspan="4" align="center">No class (MLK day)</td>
    
</tr>

<tr class="past">
    <th scope="row">1/23</th>
    
    <td>
        Lecture #3
        (Eric):
        <br>
        <strong>Representation: Undirected GMs (MRFs)</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=10-YQcNcpEETh8GAbrm2Oc4jFFO5J6q1B" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=18ZfonufLq-SvXkdITONQkh7rWt9fywxZ" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=702de16d-fb04-4906-9014-a9d0012983e2" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-03/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, Ch. 2 (Sec. 2.2 - end)</li>
        
            <li>Koller and Friedman Textbook, <a href="http://www.cs.cmu.edu/~epxing/Class/10708-17/readings/Ch%204.pdf" target="_blank">Ch. 4</a></li>
        
            <li>A. Fischer and C. Igel, <a href="https://pdfs.semanticscholar.org/dd13/5a89b5075af5cbef5becaf419457cdd77cc9.pdf" target="_blank">An Introducton to Restricted Boltzmann Machines</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">1/28</th>
    
    <td>
        Lecture #4
        (Eric):
        <br>
        <strong>Exact inference</strong> <br> - Elimination <br> - Message passing <br> - Sum product algorithm

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1CB0FIvx30B8zZYPLxirZNBxPgAR0Nj8K" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=17rDMZ_fCWCYt4z2nsIDsmQTJfMuuhBrc" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=61db95f2-aec1-415d-9180-a9d0012992fe" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-04/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, Ch. <a href="https://people.eecs.berkeley.edu/~jordan/prelims/chapter3.pdf" target="_blank">3</a> and <a href="https://people.eecs.berkeley.edu/~jordan/prelims/chapter4.pdf" target="_blank">4</a></li>
        
            <li>Koller and Friedman Textbook, <a href="https://www.cs.cmu.edu/~epxing/Class/10708-17/readings/Ch9.1-9.4.pdf" target="_blank">Ch. 9</a>, <a href="https://www.cs.cmu.edu/~epxing/Class/10708-17/readings/Ch10.1-10.3.pdf" target="_blank">Ch. 10</a></li>
        
            <li>Tom Minka, <a href="https://www.seas.harvard.edu/courses/cs281/papers/minka-divergence.pdf" target="_blank">Divergence measures and message passing</a></li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="event">HW1 out (Mon, 1/28)</span>
</p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">1/30</th>
    
    <td>
        Lecture #5
        (skipped):
        <br>
        <strong>Parameter learning in fully observable Bayesian Networks</strong> <br> - Generalized Linear Models (GLIMs) <br> - Maximum Likelihood Estimation (MLE) <br> - Markov Models

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1OrnH0oxvWUa6lsJJMeuhmrjBpW1sUDvV" target="_blank">slides</a>
            
            
            
            | video
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-05/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, Ch. 8, 9 (Sec. 9.1 - 9.2)</li>
        
            <li>Koller and Friedman Textbook, <a href="https://www.cs.cmu.edu/~epxing/Class/10708-17/readings/Ch17.1-17.4.pdf" target="_blank">Ch. 17 (Sections 17.1 - 17.4)</a></li>
        
            <li>Geiger and Heckerman, <a href="https://projecteuclid.org/euclid.aos/1035844981" target="_blank">Parameter priors for directed acyclic graphical models and the characterization of several probability distributions</a></li>
        
            <li>Geiger and Heckerman, <a href="https://projecteuclid.org/euclid.aos/1069362752" target="_blank">A characterization of the Dirichlet distribution through global and local parameter independence</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/4</th>
    
    <td>
        Lecture #6
        (Maruan):
        <br>
        <strong>Parameter Learning of partially observed BN</strong> <br> - Mixture models <br> - Hidden Markov Models (HMMs) <br> - The EM algorithm

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1m1s2SKX8cKLw-jfHFQaOksQ4ZAVtNnKU" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1wz48Vtim8d14rkjgyGJqhQxWehjGi2hy" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9e3746b9-fd53-4939-af7b-a9d00129a06f" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-06/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, Ch. 11</li>
        
            <li>Koller and Friedman Textbook, <a href="https://www.cs.cmu.edu/~epxing/Class/10708-17/readings/Ch19.1-19.4.pdf" target="_blank">Ch. 19.1-19.4</a></li>
        
            <li>Borman, <a href="https://www.cs.utah.edu/~piyush/teaching/EM_algorithm.pdf">The EM algorithm (A short tutorial)</a></li>
        
            <li><a href="http://www.cs.toronto.edu/~hinton/absps/emk.pdf" target="_blank">Some interesting aspects of the EM algorithm</a> (Neal and Hinton)</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/6</th>
    
    <td>
        Lecture #7
        (Eric):
        <br>
        <strong>Maximum likelihood learning of undirected GM</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=115xuxWPNP6x1yFY0HxR8U5bQrigOXxDh" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=19B19NypHAaxo_eud6lQBsZl63Fdwv3lJ" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=d004814a-0054-49c6-9a2b-a9d00129aa04" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-07/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, Ch. 9 (Sec. 9.3-9.5), Ch. 20</li>
        
            <li>Friedman, Hastie, Tibshirani. <a href="http://statweb.stanford.edu/~tibs/glasso/" target="_blank">Sparse inverse covariance estimation with the graphical lasso</a>.</li>
        
            <li>Lafferty et al., <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.803&amp;rep=rep1&amp;type=pdf" target="_blank">Conditional Random Fields - Probabilistic Models for Segmenting and Labeling Sequence Data</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/11</th>
    
    <td>
        Lecture #8
        (guest lecture, <a href="https://www.cmu.edu/dietrich/philosophy/people/faculty/zhang.html" target="_blank">Kun Zhang</a> @ Department of Philosophy):
        <br>
        <strong>Causal discovery and inference</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1pXvKPXUcOHPFff0RsUvEUmTLMeXuPQQV" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=51529b86-51dd-41eb-840f-a9d00129b93c" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-08/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>J. Pearl, M. Glymour, and N. P. Jewell. <a href="http://bayes.cs.ucla.edu/PRIMER/" target="_blank">Causal Inference in Statistics A Primer</a>. Concepts related to causality and identification of causal effects.</li>
        
            <li>P. Spirtes, C. Glymour, and R. Scheines. <a href="https://www.researchgate.net/publication/242448131_Causation_Prediction_and_Search" target="_blank">Causation, Prediction, and Search</a>. Pages 80-89 and 125-123-136. Traditional methods for causal discovery, including the PC and FCI algorithms.</li>
        
            <li>K. Zhang, B. Schöklopf, P. Spirtes, and C. Glymour. <a href="https://academic.oup.com/nsr/article/5/1/26/4638533" target="_blank">Learning causality and causality-related learning</a>. Brief review of recent methods for causal discovery.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/13</th>
    
    <td>
        Lecture #9
        (Eric):
        <br>
        <strong>Modeling networks</strong> <br> - Gaussian graphical models <br> - Ising models

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1lcnsthY3Dkqz1zUcTSuhIt3jRiLYiWG5" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1zBulUpIRgribFM-taC_-4kmcI7migrQ_" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=2005749e-7531-473e-adb6-a9d00129c5e1" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-09/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Meinshausen and Buhlmann, <a href="https://projecteuclid.org/euclid.aos/1152540754" target="_blank">High-Dimensional Graphs and Variable Selection with the Lasso</a>.</li>
        
            <li>Kolar et al., <a href="https://www.cs.cmu.edu/~epxing/papers/2010/kolar_song_xing_aoas10.pdf" target="_blank">Estimating Time-Varying Networks</a>.</li>
        
            <li>Dempster, <a href="https://www.jstor.org/stable/2528966?origin=JSTOR-artinfo&amp;seq=1#page_scan_tab_contents" target="_blank">Covariance Selection</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="deadline">HW1 due (Wed, 2/13)</span>
</p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/18</th>
    
    <td>
        Lecture #10
        (Eric):
        <br>
        <strong>Sequential models</strong> <br> - Discrete Hidden State (HMM vs. CRF) <br> - Continuous Hidden State (Kalman Filter)

        <br>
        [
            
              <a href="https://drive.google.com/open?id=16d3NssHP_N5WH8ohecdmtwYjZt097Yjh" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1y0PodJ6ar-54CfXxcKw82kSnkYMJdStl" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=77665f85-3445-4146-b0c6-a9d00129cf56" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-10/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, Ch. 14, Ch. 15</li>
        
            <li>Ng, <a href="http://cs229.stanford.edu/notes/cs229-notes9.pdf" target="_blank">Lecture notes on factor analysis</a>.</li>
        
            <li>Welch and Bishop, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.6578&amp;rep=rep1&amp;type=pdf" target="_blank">An Introduction to the Kalman Filter</a>.</li>
        
            <li><a href="https://people.cs.umass.edu/~wallach/technical_reports/wallach04conditional.pdf" target="_blank">Conditional Random Fields - An Introduction</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="info">
    <td colspan="5" align="center"><strong>Module 2: Approximate Inference</strong></td>
</tr>

<tr class="past">
    <th scope="row">2/20</th>
    
    <td>
        Lecture #11
        (Eric):
        <br>
        <strong>Approximate Inference: Mean Field (MF) and loopy Belief Propagation (BP) approximations</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1qUNGOr3GUzMDEBWGajk4nyC70qS1sgje" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1S05cgP_qeceFDM_vSNozamcBhKhyV1mf" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=f0ffcd91-f4a6-4321-8595-a9d00129da6e" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-11/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Yedidia et al., <a href="http://papers.nips.cc/paper/1832-generalized-belief-propagation.pdf" target="_blank">Generalized Belief Propagation</a>.</li>
        
            <li>Xing et al., <a href="http://www.cs.berkeley.edu/~russell/papers/uai03-gmf.pdf" target="_blank">A Generalized Mean Field Algorithm for Variational Inference in Exponential Families</a>.</li>
        
            <li><a href="https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf" target="_blank">Variational inference tutorial (NIPS 2016)</a></li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="event">HW2 out (Fri, 2/22)</span> <br> <span class="deadline">Project proposal due (Fri, 2/22)</span>
</p>
    </td>
    
</tr>

<tr class="warning">
    <th scope="row">2/25</th>
    
    <td>
        Lecture #12
        (Eric):
        <br>
        <strong>Theory of Variational Inference: Inner and Outer Approximations</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1lrTb1S_jNcN__ftEp3qH7fR-VgenTTss" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1A8bK1lwxyMr1WolBFqOc_usNEBZyVP2p" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=45100737-122a-4087-9088-a9d0012c1e1f" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-12/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Wainwright and Jordan, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.61.4581&amp;rep=rep1&amp;type=pdf" target="_blank">Variational Inference in Graphical Models - The View from the Marginal Polytope</a>.</li>
        
            <li>Wainwright and Jordan, <a href="http://www.eecs.berkeley.edu/~wainwrig/Papers/WaiJor08_FTML.pdf" target="_blank">Graphical Models, Exponential Families, and Variational Inference</a> (Sec. 3 and 4).</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">2/27</th>
    
    <td>
        Lecture #13
        (Eric):
        <br>
        <strong>Approximate Inference: Monte Carlo and Sequential Monte Carlo methods</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=15BWU6u1mlKBR3OW7PcPN5W3G49vmTHPw" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1bQvXnceyWdeOR7t1g0VU8HQSI4xBFUQ7" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ed8bdd59-b55e-42b4-be99-a9d0012c953d" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-13/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Jordan Textbook, Ch. 21</li>
        
            <li>David MacKay's Textbook, <a href="http://www.inference.phy.cam.ac.uk/itprnn/book.pdf#page=368" target="_blank">Ch. 29</a> (Sec. 29.1-29.3).</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">3/4</th>
    
    <td>
        Lecture #14
        (Eric):
        <br>
        <strong>Markov Chain Monte Carlo</strong> <br> - Metropolis-Hastings <br> - Hamiltonian Monte Carlo <br> - Langevin Dynamics

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1jmGlIpDJ5f-Oz9GAY13vJDu81zwZAGJQ" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1gcYHfoJzpvbE7yhioVQgTyOswFQ9MUR3" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=725d390e-9176-4a16-919b-a9d0012ccd9a" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-14/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>David MacKay's Textbook, <a href="http://www.inference.phy.cam.ac.uk/itprnn/book.pdf#page=368" target="_blank">Ch. 29</a> (Sec. 29.4-29.10).</li>
        
            <li>Neal, <a href="https://arxiv.org/pdf/1206.1901.pdf" target="_blank">MCMC using Hamiltonian dynamics</a>.</li>
        
            <li>Patterson and Teh, <a href="http://papers.nips.cc/paper/4883-stochastic-gradient-riemannian-langevin-dynamics-on-the-probability-simplex.pdf" target="_blank">Stochastic Gradient Riemannian Langevin Dynamics on the Probability Simplex</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="info">
    <td colspan="5" align="center"><strong>Module 3: Deep Learning &amp; Generative Models</strong></td>
</tr>

<tr class="upcoming">
    <th scope="row">3/6</th>
    
    <td>
        Lecture #15
        (Eric):
        <br>
        <strong>Statistical and Algorithmic Foundations of Deep Learning</strong> <br> - Insight into DL <br> - Connections to GM

        <br>
        [
            
              <a href="https://drive.google.com/open?id=17GHo4zlUF0cCgfP8twNQjA2DERN8nYi4" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1VZczo_5_Qr0669Jvcf_ImS_h4YCXg2Nk" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=caa6ce42-b7b9-4145-bc4c-a9d0012ce923" target="_blank">video</a>
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li><a href="http://www.deeplearningbook.org/" target="_blank">Deep learning book</a>, Ch. 6.2-5, 20.3-4.</li>
        
            <li>Salakhutdinov and Hinton, <a href="http://www.jmlr.org/proceedings/papers/v5/salakhutdinov09a/salakhutdinov09a.pdf" target="_blank">Deep Boltzmann machines</a>.</li>
        
            <li>Belanger and McCallum, <a href="https://people.cs.umass.edu/~belanger/belanger_spen_icml.pdf" target="_blank">Structured prediction energy networks</a>.</li>
        
            <li>Ranganath et al., <a href="http://www.jmlr.org/proceedings/papers/v38/ranganath15.pdf" target="_blank">Deep exponential families</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="deadline">HW2 due (Mon, 3/11)</span>
</p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">3/11</th>
    
    
    <td colspan="4" align="center">No classes (Spring break)</td>
    
</tr>

<tr class="upcoming">
    <th scope="row">3/13</th>
    
    
    <td colspan="4" align="center">No classes (Spring break)</td>
    
</tr>

<tr class="upcoming">
    <th scope="row">3/18</th>
    
    <td>
        Lecture #16
        (guest lecture, <a href="https://www.cs.cmu.edu/~zhitingh/" target="_blank">Zhiting Hu</a>):
        <br>
        <strong>Building blocks of DL</strong> <br> - RNN and LSTM <br> - CNN, Transformers <br> - Attention mechanisms <br> - (Case studies in NLP)

        <br>
        [
            
              <a href="https://drive.google.com/open?id=18IPM6j9aTSqatD-p7UBOA4GDA0b63Xzh" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=1a0b496e-fc7c-4abd-bcdc-aa140107f167" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-16/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Pascanu, Mikolov, Bengio, <a href="http://proceedings.mlr.press/v28/pascanu13.pdf" target="_blank">On the difficulty of training recurrent neural networks</a>.</li>
        
            <li>Vasvani et al., <a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank">Attention is all you need</a>.</li>
        
            <li>Devlin et al., <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank">BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="event">HW3 out (Mon, 3/18)</span>
</p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">3/20</th>
    
    <td>
        Lecture #17
        (Eric):
        <br>
        <strong>Deep generative models (part 1): <br> Overview of the theoretical basis and connections of deep generative models</strong> <br> - Wake sleep algorithm <br> - Variational autoencoders <br> - Generative adversarial networks <br> - A unified view of DGM

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1zj9GZ6D8fXwZ3xPibNbcKQ0zJhFHCSHt" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=e48fed41-d33a-429a-880a-a9d0012d041a" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-17/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li><a href="http://www.deeplearningbook.org/" target="_blank">Deep learning book</a>, Ch. 20.9-10</li>
        
            <li>Variational Autoencoders, <a href="https://arxiv.org/abs/1312.6114" target="_blank">Kingma and Welling, 2014</a>.</li>
        
            <li>Generative Adversarial Nets, <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" target="_blank">Goodfellow et al., 2014</a>.</li>
        
            <li>Sanjeev Arora's <a href="http://www.offconvex.org/2017/03/15/GANs/" target="_blank">blog post on GANs</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">3/25</th>
    
    <td>
        Lecture #18
        (guest lecture, <a href="https://www.cs.cmu.edu/~zhitingh/" target="_blank">Zhiting Hu</a>):
        <br>
        <strong>Deep generative models (part 2)</strong> <br> - GANs and their variations <br> - Normalizing Flows <br> - Integrating domain knowledge in DL

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1mt2-j8yn1EgNXD-TDJ_qITfYvI1fjUEh" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=231412f0-243a-4d82-9441-a9d0012d9aa7" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-18/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Arjovsky, Bottou, <a href="https://arxiv.org/pdf/1701.04862.pdf" target="_blank">Towards principled methods for training generative adversarial networks</a>.</li>
        
            <li>Kingma, Dhariwal, <a href="https://arxiv.org/pdf/1807.03039.pdf" target="_blank">Glow - Generative Flow with Invertible 1x1 Convolutions</a>.</li>
        
            <li>Hu et al., <a href="https://arxiv.org/pdf/1603.06318.pdf" target="_blank">Harnessing Deep Neural Networks with Logic Rules</a>.</li>
        
            <li>Hu et al., <a href="http://papers.nips.cc/paper/8250-deep-generative-models-with-learnable-knowledge-constraints.pdf" target="_blank">Deep Generative Models with Learnable Knowledge Constraints</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">3/27</th>
    
    <td>
        Lecture #19
        (guest lecture, <a href="https://www.cs.cmu.edu/~zhitingh/" target="_blank">Zhiting Hu</a>):
        <br>
        <strong>Case Study: Text Generation</strong> <br> - The encoder-decoder framework <br> - Machine translation as conditional generation <br> - Unifying MLE and RL objectives for text generation

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1DMgamXeDX9I-YiOgcGZJzhwdWqP2Ubzb" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=8e1ca7f0-811c-493b-98f7-aa1600c828e5" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-19/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Ranzato et al., <a href="https://arxiv.org/pdf/1511.06732.pdf" target="_blank">Sequence Level Training with Recurrent Neural Networks</a>.</li>
        
            <li>Hu et al., <a href="https://arxiv.org/pdf/1703.00955.pdf" target="_blank">Toward Controlled Generation of Text</a>.</li>
        
            <li>Tan, Hu et al., <a href="https://arxiv.org/pdf/1811.09740.pdf" target="_blank">Connecting the Dots Between MLE and RL for Sequence Generation</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="deadline">Midway report due (Fri, 3/29)</span>
</p>
    </td>
    
</tr>

<tr class="info">
    <td colspan="5" align="center"><strong>Module 4: Reinforcement Learning &amp; Control Through Inference in GM</strong></td>
</tr>

<tr class="upcoming">
    <th scope="row">4/1</th>
    
    <td>
        Lecture #20
        (Maruan):
        <br>
        <strong>Sequential decision making (part 1): The framework</strong> <br> - Brief introduction to reinforcement learning (RL) <br> - Connections to GM: RL and control as inference <br> - Control via Variational Inference

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1Fke2GD8etptzMdVE32wtJL3EvtjidtCV" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1kGvJ1ywU5lCh9Fdo19xdaG4hKqwzOC5_" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=63c27723-7630-42ee-93c2-aa2201091059" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-20/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Sutton, Barto, <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">Reinforcement Learning, An Introduction</a>, Ch. 3, 4.</li>
        
            <li>Lilian Weng, <a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html" target="_blank">A peek into RL (blog)</a>.</li>
        
            <li>Levine, <a href="https://arxiv.org/abs/1805.00909" target="_blank">Reinforcement Learning and Control as Probabilistic Inference</a>, Sec. 1-3.</li>
        
            <li>Ziebart, <a href="https://www.cs.cmu.edu/~bziebart/publications/thesis-bziebart.pdf" target="_blank">Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy</a>, Ch. 5.1-2, 6.1-2.</li>
        
            <li>Todorov, <a href="http://folk.ntnu.no/skoge/prost/proceedings/cdc-2008/data/papers/1788.pdf" target="_blank">General duality between optimal control and estimation</a>.</li>
        
            <li>Koller and Friedman Textbook, Ch. 20.3.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">4/3</th>
    
    <td>
        Lecture #21
        (Maruan):
        <br>
        <strong>Sequential decision making (part 2): The algorithms</strong> <br> - Intro to RL algorithms: policy gradients and Q-learning <br> - Max-entropy policy gradient <br> - Soft Q-learning

        <br>
        [
            
              <a href="https://www.dropbox.com/s/bw3lazuqj141v9a/lecture21-RL%2BPGM-part2-maruan.pdf?dl=0" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1fkik31NBSShmuvXdbWik5jz2MWeTXQsr" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=241c108f-bb4b-4feb-909b-a9d0012dd93a" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-21/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Sutton, Barto, <a href="http://incompleteideas.net/book/RLbook2018.pdf" target="_blank">Reinforcement Learning, An Introduction</a>, Ch. 13.</li>
        
            <li>Levine, <a href="https://arxiv.org/abs/1805.00909" target="_blank">Reinforcement Learning and Control as Probabilistic Inference</a>, Sec. 4.</li>
        
            <li>Haarnoja et al., <a href="https://arxiv.org/pdf/1702.08165.pdf" target="_blank">Reinforcement Learning with Deep Energy-Based Policies</a>.</li>
        
            <li>Haarnoja et al., <a href="https://arxiv.org/pdf/1801.01290.pdf" target="_blank">Soft Actor-Critic</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="deadline">HW3 due (Wed, 4/3)</span>
</p>
    </td>
    
</tr>

<tr class="info">
    <td colspan="5" align="center"><strong>Module 5: Nonparametric methods</strong></td>
</tr>

<tr class="upcoming">
    <th scope="row">4/8</th>
    
    <td>
        Lecture #22
        (Eric):
        <br>
        <strong>Bayesian non-parameterics</strong> <br> - Dirichlet Process (DP) <br> - Indian Buffet Process (IBP)

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1nK8hoBIJqzkyFfavABngyXsi2WEMnfJV" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1y3qtLiF-Ja6VIeSSjjR69TYzTAoSDTW-" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=446e2313-d65b-406c-b893-aa1600c8564d" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-22/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Teh, <a href="http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf" target="_blank">Dirichlet Process</a>.</li>
        
            <li>Griffiths and Ghahramani, <a href="http://jmlr.csail.mit.edu/papers/volume12/griffiths11a/griffiths11a.pdf" target="_blank">The Indian Buffet Process</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="event">HW4 out (Mon, 4/8)</span>
</p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">4/10</th>
    
    <td>
        Lecture #23
        (Maruan):
        <br>
        <strong>Bayesian non-parameterics (continued)</strong> <br> - Inference in Dirichlet Process (DP) <br> - Hierarchical Dirichlet Process (HDP) <br> - Indian Buffet Process (IBP)

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1uVW2vjEL1f6l4m9BVVqf2IX1h9jBrN8J" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5aee3315-845f-4022-8c57-aa1600c86513" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-23/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li><a href="https://dp.tdhopper.com/" target="_blank">Notes on Dirichlet Processes</a>.</li>
        
            <li>Ishwaran, James, <a href="http://people.ee.duke.edu/~lcarin/Yuting3.3.06.pdf" target="_blank">Gibbs Sampling Methods for Stick-Breaking Priors</a>.</li>
        
            <li>Teh, Jordan, Beal, Blei, <a href="https://people.eecs.berkeley.edu/~jordan/papers/hdp.pdf" target="_blank">Hierarchical Dirichlet Process</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">4/15</th>
    
    <td>
        Lecture #24
        (Eric):
        <br>
        <strong>Integrative Paradigms of GM: Regularized Bayesian Methods</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1EzldiYU29eBOG6Mo4WrxdrgZRTGYVLvx" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=1GMHdLd8qHYlVH7ehPFsqMs76YbusziKu" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=b418dd05-cafc-4d6e-bebf-aa1600c873a8" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-24/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Ganchev, Graça, Gillenwater, Taskar. <a href="http://www.jmlr.org/papers/volume11/ganchev10a/ganchev10a.pdf" target="_blank">Posterior Regularization for Structured Latent Variable Models</a>.</li>
        
            <li>Zhu, Chen, Xing. <a href="http://www.jmlr.org/papers/volume15/zhu14b/zhu14b.pdf" target="_blank">Bayesian Inference with Posterior Regularization and Applications to Infinite Latent SVMs</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">4/17</th>
    
    <td>
        Lecture #25
        (Eric):
        <br>
        <strong>Elements of Spectral &amp; Kernel GMs</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1sPBzB2wXIYrnhIRH9V8umZ0FpJih4g46" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=128szgy7kOuWj-7kwW5-0PBW_PREd35Gm" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=49837ef3-3e49-4298-8a9e-aa1600c8843e" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-25/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Song. <a href="http://www.cc.gatech.edu/~lsong/papers/lesong_thesis.pdf">Learning via Hilbert space embedding of distributions</a>, Sec. 2.1, 2.2, 3.1, 3.2.</li>
        
            <li>Hsu, Kakade, Zhang. <a href="https://arxiv.org/pdf/0811.4413v6.pdf" target="_blank">A Spectral Algorithm for Learning Hidden Markov Models</a>.</li>
        
            <li>Song, Liu, Parikh, Xing. <a href="https://arxiv.org/abs/1401.3940" target="_blank">Nonparametric latent tree graphical models</a>.</li>
        
            <li>Parikh, Song, Xing. <a href="http://www.cs.cmu.edu/~epxing/papers/2011/Parikh_Song_Xing_ICML11.pdf" target="_blank">A Spectral Algorithm for Latent Tree Graphical Models</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">4/22</th>
    
    <td>
        Lecture #26
        (Maruan):
        <br>
        <strong>Gaussian processes (GPs) and elements of meta-learning</strong> <br> - Gaussian Processes (GPs) and kernel functions <br> - (Deep) kernel learning and approximations <br> - Neural Processes (NPs) as an approximation to GPs <br> - Elements of meta-learning

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1ZMm59tO1f956YRY1EpZHMVi4PhYpnB1u" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a5dcf74f-9c2d-4306-a916-aa1600c89407" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-26/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Rasmussen, Williams. <a href="http://www.gaussianprocess.org/gpml/" target="_blank">Gaussian Processes for Machine Learning</a>, Ch. 2.2-2.4, 4.1-4.2.</li>
        
            <li>Görtler, Kehlbeck, Deussen. <a href="https://distill.pub/2019/visual-exploration-gaussian-processes/" target="_blank"> A Visual Exploration of Gaussian Processes</a>.</li>
        
            <li>Wilson, Hu, Salakhutdinov, Xing. <a href="https://arxiv.org/abs/1511.02222" target="_blank">Deep Kernel Learning</a>.</li>
        
            <li>Garnelo et al. <a href="https://arxiv.org/abs/1807.01613" target="_blank">Conditional</a> <a href="https://arxiv.org/abs/1807.01622" target="_blank">Neural Processes</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="info">
    <td colspan="5" align="center"><strong>Module 6: Modular and scalable algorithms and systems</strong></td>
</tr>

<tr class="upcoming">
    <th scope="row">4/24</th>
    
    <td>
        Lecture #27
        (guest lecture, <a href="https://sites.google.com/site/hoqirong/" target="_blank">Qirong Ho</a>):
        <br>
        <strong>Scalable algorithms and systems for learning, inference, and prediction</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=1ogZ6BEGb9wJhymRPXPtBmBw8Wirs7bhv" target="_blank">slides</a>
            
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=b944a404-0d3e-4668-b7c3-aa3701087dfe" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-27/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Bradley et al. (2011). <a href="http://www.select.cs.cmu.edu/publications/paperdir/icml2011-bradley-kyrola-bickson-guestrin.pdf" target="_blank">Parallel Coordinate Descent for L1-Regularized Loss Minimization</a>.</li>
        
            <li>Yuan et al. (2015). <a href="https://daiwei89.github.io/papers/lightlda.pdf" target="_blank">LightLDA - Big Topic Models on Modest Computer Clusters</a>.</li>
        
            <li>Ho et al. (2013). <a href="http://papers.nips.cc/paper/4894-more-effective-distributed-ml-via-a-stale-synchronous-parallel-parameter-server.pdf" target="_blank">More effective distributed ML via a stale synchronous parallel parameter server</a>.</li>
        
            <li>Kim et al. (2016). <a href="https://dl.acm.org/citation.cfm?id=2901331" target="_blank">STRADS - A Distributed Framework for Scheduled Model Parallel Machine Learning</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p><span class="deadline">HW4 due (Mon, 4/24)</span>
</p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">4/29</th>
    
    <td>
        Lecture #28
        (Eric):
        <br>
        <strong>A civil engineering perspective on AI</strong>

        <br>
        [
            
              <a href="https://drive.google.com/open?id=11jj5XNJFWtu3jxI7nu1tEaRXJfaNrHds" target="_blank">slides</a>
            
            
              (<a href="https://drive.google.com/open?id=18uGQ6AP-tvWKAVw0XOv3vsqYz19OC3e6" target="_blank">annotated</a>)
            
            
            | <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=c4f50fb4-29e0-4403-b57f-aa370108c04e" target="_blank">video</a>
            
            
            | <a href="https://sailinglab.github.io/pgm-spring-2019/notes/lecture-28/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Xing et al. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7239545" target="_blank">Petuum - A New Platform for Distributed Machine Learning on Big Data</a>.</li>
        
            <li>Xing et al. <a href="https://www.cs.cmu.edu/~epxing/papers/2016/Xing_Engineering16.pdf" target="_blank">Strategies and Principles of Distributed Machine Learning on Big Data</a>.</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="upcoming">
    <th scope="row">4/30</th>
    
    
    <td colspan="4" align="center">Project presentations (NSH attrium, 2:30-5:30 pm)</td>
    
</tr>


      </tbody>
    </table>
  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Probabilistic Graphical Models</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">SAILING lab</li><li><a class="u-email" href="mailto:10708-instructor@cs.cmu.edu">10708-instructor@cs.cmu.edu</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/sailinglab" target="_blank"><i class="fab fa-github"></i> <span class="username">sailinglab</span></a></li><li><a href="https://www.youtube.com/channel/UCim-E6bNz7lUyKZwhgN6S1A" target="_blank"><i class="fab fa-youtube"></i> <span class="username">YouTube</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>© Copyright 2020 Carnegie Mellon University. <br>
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
</p>
      </div>
    </div>

  </div>

</footer>


    <!-- Load jQuery -->
<script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/jquery-1.12.4.min.js.download"></script>

<!-- Load Common JS -->
<script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/common.js.download"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/katex.min.css">
<script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/katex.min.js.download"></script>
<script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/katex.js.download"></script>



<!-- Load Anchor JS -->
<script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/anchor.min.js.download"></script>
<script>
  anchors.options.visible = 'hover';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>



<!-- Adjust LaTeX JS -->
<script src="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/latex.js.download"></script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/fontawesome-all.min.css">
<link rel="stylesheet" href="./10-708-probabilistic-graphical-models-course-schedule-spring-2019_files/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-131744305-1', 'auto');
ga('send', 'pageview');
</script>


  


<svg id="SvgjsSvg1001" width="2" height="0" xmlns="http://www.w3.org/2000/svg" version="1.1" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:svgjs="http://svgjs.com/svgjs" style="overflow: hidden; top: -100%; left: -100%; position: absolute; opacity: 0;"><defs id="SvgjsDefs1002"></defs><polyline id="SvgjsPolyline1003" points="0,0"></polyline><path id="SvgjsPath1004" d="M0 0 "></path></svg></body></html>